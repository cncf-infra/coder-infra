#+title: Coder Infra

#+begin_quote
Infrastructure to support a Coder instance, provided by CNCF, for the use of contributors
#+end_quote

* Project contents
- Terraform to provision Kubernetes resources to a cluster

* Architecture
Deploy a Kubernetes cluster running on Equinix Metal which runs Coder server.

Running in the cluster will be
- Cert-Manager
- Nginx-Ingress :: serve services like Coder server
- MetalLB :: BGP IP allocation
- PowerDNS :: use to allow setting up of DNS01 validation for TLS certs
- distribution(s) :: use as a proxy cache for each common registry to save bandwidth and time
- External-DNS :: manage DNS in a Kubernetes-native way
- a CSI provider :: storage!
- kubevirt :: vms
- cluster-api :: orchestrate Kubernetes in Kubernetes
- Coder :: the server itself

The domain /coder.sharing.io/ is where Coder lives.
/*.coder.sharing.io/ is to point also to the same IP as Coder.

An NS record links the managed records in the DNS provider to the PowerDNS in the cluster
#+begin_src
NS 	coder.sharing.io 	ns1.coder.sharing.io
#+end_src

* Needs
- [ ] completion of architecture
- [x] a domain to use for hosting
- [ ] do cluster-api and kubevirt components live in the management cluster?

* todo
- [x] configure and deploy powerdns
- [x] configure and deploy external-dns, point it to powerdns
- [x] create a cert and cluster-issuer for /coder.sharing.io/ and /*.coder.sharing.io/
- [x] set up NS DNS record on sharing.io DNS provider
- [x] configure storage (https://github.com/cncf-infra/coder-infra/issues/1)
- [ ] configure and deploy kubevirt
- [ ] deploy cluster-api
- [ ] configure and deploy Coder

* Prerequisites

ytt, for YAML updating
#+begin_src shell :results silent
go install github.com/vmware-tanzu/carvel-ytt/cmd/ytt@v0.43.0
#+end_src

* Setup
A Kubernetes cluster is required to initialise the target cluster.

Either use an existing cluster or create a ~kind~ cluster
#+begin_src tmate :window coder-infra
kind create cluster
#+end_src

Set credentials for Equinix Metal for initialising the cluster-api provider
#+begin_src tmate :window coder-infra
read PACKET_API_KEY; export PACKET_API_KEY
#+end_src

Initialise cluster-api with the Packet (Equinix Metal) infrastructure provider
#+begin_src tmate :window coder-infra
clusterctl init --infrastructure packet --bootstrap talos --control-plane talos
#+end_src

List the variables used in the cluster configuration
#+begin_src shell
clusterctl generate cluster --infrastructure packet --list-variables cluster-template.yaml 2>/dev/null
#+end_src

#+RESULTS:
#+begin_example
Required Variables:
  - CONTROLPLANE_NODE_TYPE
  - FACILITY
  - PROJECT_ID
  - SSH_KEY
  - WORKER_NODE_TYPE

Optional Variables:
  - CLUSTER_NAME                 (defaults to cluster-template.yaml)
  - CONTROL_PLANE_MACHINE_COUNT  (defaults to 1)
  - CPEM_VERSION                 (defaults to "v3.5.0")
  - KUBERNETES_VERSION           (defaults to 1.23.5)
  - NODE_OS                      (defaults to "ubuntu_18_04")
  - POD_CIDR                     (defaults to "192.168.0.0/16")
  - SERVICE_CIDR                 (defaults to "172.26.0.0/16")
  - WORKER_MACHINE_COUNT         (defaults to 0)

#+end_example

Generate a static cluster configuration
#+begin_src tmate :window coder-infra
export CONTROLPLANE_NODE_TYPE=c3.small.x86 \
  WORKER_NODE_TYPE=c3.small.x86 \
  FACILITY=sv15 \
  PROJECT_ID=7a44b778-41d2-49fa-9c92-99148516c600 \
  SSH_KEY=gh:BobyMCbobs \
  TALOS_VERSION=v1.2.6 \
  KUBERNETES_VERSION=v1.24.8 \
  NODE_OS=ubuntu_20_04 \
  SERVICE_CIDR=10.96.0.0/12 \
  POD_CIDR=10.244.0.0/16 \
  CONTROL_PLANE_MACHINE_COUNT=3
clusterctl generate cluster cncf-coder --target-namespace cncf-coder --from ./cluster-template-packet-kubeadm.yaml \
    > ./cluster-cncf-coder-infra.yaml
#+end_src

* Installation
#+begin_src shell
kubectl apply -f ./cluster-cncf-coder-namespace.yaml
kubectl -n cncf-coder apply -f ./cluster-cncf-coder-infra.yaml
#+end_src

#+RESULTS:
#+begin_example
namespace/cncf-coder created
kubeadmcontrolplane.controlplane.cluster.x-k8s.io/cncf-coder-control-plane created
packetmachinetemplate.infrastructure.cluster.x-k8s.io/cncf-coder-control-plane created
cluster.cluster.x-k8s.io/cncf-coder created
packetcluster.infrastructure.cluster.x-k8s.io/cncf-coder created
machinedeployment.cluster.x-k8s.io/cncf-coder-worker-a created
packetmachinetemplate.infrastructure.cluster.x-k8s.io/cncf-coder-worker-a created
kubeadmconfigtemplate.bootstrap.cluster.x-k8s.io/cncf-coder-worker-a created
#+end_example

* Watch provisioning
#+begin_src tmate :window coder-infra
kubectl -n cncf-coder get packetmachine,machine,taloscontrolplane,secret,cm
#+end_src

* Fetch Kubeconfig
#+begin_src shell :results silent
kubectl -n cncf-coder get secret cncf-coder-kubeconfig -o=jsonpath='{.data.value}' | base64 -d > /tmp/cncf-coder-kubeconfig
#+end_src

* Mark as schedulable
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig taint nodes --all node-role.kubernetes.io/master-
#+end_src

* Prepare
Cert-Manager
#+begin_src shell :results silent
curl -o ./cert-manager.yaml -L https://github.com/cert-manager/cert-manager/releases/download/v1.10.0/cert-manager.yaml
#+end_src

Cilium
#+begin_src shell
helm repo add cilium https://helm.cilium.io/
helm template cilium cilium/cilium \
    --version 1.11.6 \
    --namespace kube-system \
    -f ./values/cilium.yaml \
    > ./cilium.yaml
#+end_src

#+RESULTS:
#+begin_example
"cilium" already exists with the same configuration, skipping
#+end_example

Metallb
#+begin_src shell :results silent
helm repo add metallb https://metallb.github.io/metallb
helm template --create-namespace -n metallb-system metallb metallb/metallb --version 0.13.7 --values values/metallb.yaml \
    > ./metallb.yaml
#+end_src

ingress-nginx
#+begin_src shell
export LB_IP="$(kubectl --kubeconfig /tmp/cncf-coder-kubeconfig -n kube-system get service cloud-provider-equinix-metal-kubernetes-external -o=jsonpath='{.status.loadBalancer.ingress[0].ip}')"

helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm template -n ingress-nginx ingress-nginx ingress-nginx/ingress-nginx --version 4.4.0 --values ./values/ingress-nginx.yaml --set controller.service.externalIPs[0]="$LB_IP" > ./ingress-nginx.yaml
#+end_src

#+RESULTS:
#+begin_example
"ingress-nginx" already exists with the same configuration, skipping
#+end_example

Longhorn
#+begin_src shell :results silent
helm repo add longhorn https://charts.longhorn.io
helm template longhorn longhorn/longhorn --values values/longhorn.yaml --namespace longhorn-system --version 1.3.2 \
    > ./longhorn-pre.yaml
cat ./longhorn-pre.yaml | ytt --ignore-unknown-comments -f overlays/ -f - > ./longhorn.yaml
rm ./longhorn-pre.yaml
#+end_src

* Install
#+begin_src shell
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig create namespace coder
#+end_src

#+RESULTS:
#+begin_example
namespace/coder created
#+end_example

Cilium
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f ./cilium.yaml
#+end_src

Longhorn
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig create namespace longhorn-system --dry-run=client -o yaml \
  | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f ./longhorn.yaml
#+end_src

Cert-Manager
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f ./cert-manager.yaml
#+end_src

metallb
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig create namespace metallb-system --dry-run=client -o yaml \
  | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig -n metallb-system apply -f metallb.yaml
#+end_src

ingress-nginx
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig create namespace ingress-nginx --dry-run=client -o yaml \
  | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -n ingress-nginx -f ./ingress-nginx.yaml
#+end_src

PowerDNS
#+begin_src shell :results silent
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig create namespace powerdns --dry-run=client -o yaml \
  | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
export LB_IP="$(kubectl --kubeconfig /tmp/cncf-coder-kubeconfig -n kube-system get service cloud-provider-equinix-metal-kubernetes-external -o=jsonpath='{.status.loadBalancer.ingress[0].ip}')"
envsubst '${LB_IP}' < ./powerdns.yaml | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
#+end_src

Certs
#+begin_src shell :results silent
export LB_IP="$(kubectl --kubeconfig /tmp/cncf-coder-kubeconfig -n kube-system get service cloud-provider-equinix-metal-kubernetes-external -o=jsonpath='{.status.loadBalancer.ingress[0].ip}')"
envsubst '${LB_IP}' < ./certs.yaml | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
#+end_src

External-DNS
#+begin_src shell :results silent
export LB_IP="$(kubectl --kubeconfig /tmp/cncf-coder-kubeconfig -n kube-system get service cloud-provider-equinix-metal-kubernetes-external -o=jsonpath='{.status.loadBalancer.ingress[0].ip}')"
kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f ./external-dns-crd.yaml
envsubst '${LB_IP}' < ./external-dns.yaml | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
envsubst '${LB_IP}' < ./dnsendpoint.yaml | kubectl --kubeconfig /tmp/cncf-coder-kubeconfig apply -f -
#+end_src

* Tear down
#+begin_src shell
kubectl -n cncf-coder delete cluster cncf-coder
kubectl delete ns cncf-coder
#+end_src

#+RESULTS:
#+begin_example
cluster.cluster.x-k8s.io "cncf-coder" deleted
namespace "cncf-coder" deleted
#+end_example
